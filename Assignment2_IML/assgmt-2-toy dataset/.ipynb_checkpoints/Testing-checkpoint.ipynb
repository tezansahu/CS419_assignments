{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "class DataLoader(object):\n",
    "    # this class has a standard iterator declared\n",
    "    # __len__ returns the number of batches (size of the object)\n",
    "    # __get_item__ handles integer based indexing of the object \n",
    "    def __init__(self, data_file, batch_size):\n",
    "        with open(data_file, 'r') as df:\n",
    "            data = df.readlines()\n",
    "\n",
    "        data = data[1:]\n",
    "        data = data[:(len(data)//batch_size)*batch_size]\n",
    "        np.random.shuffle(data)\n",
    "        data = np.array([[float(col) for col in row.split(',')] for row in data])\n",
    "        input_data, targets = data[:, :-1], data[:, -1]\n",
    "        input_data = np.hstack([input_data, np.ones((len(input_data), 1), dtype=np.float32)])\n",
    "\n",
    "        self.num_features = input_data.shape[1]\n",
    "        self.current_batch_index = 0\n",
    "        self.input_batches = np.split(input_data, len(input_data)//batch_size)\n",
    "        self.target_batches = np.split(targets, len(targets)//batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_batches)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "\n",
    "        batch_input_data = self.input_batches[i]\n",
    "        batch_targets = self.target_batches[i]\n",
    "        return batch_input_data, batch_targets\n",
    "\n",
    "def classify(inputs, weights):\n",
    "    #this functions returns w^Tx . The output  is batch_size*1\n",
    "\treturn np.dot(inputs, np.reshape(weights, (np.size(weights), 1)).reshape((-1,)))\n",
    "\n",
    "def get_objective_function(trainx,trainy,loss_type, regularizer_type, loss_weight):\n",
    "    # this function calculates the loss for a current batch\n",
    "    loss_function = utils.loss_functions[loss_type]\n",
    "    if regularizer_type != None:\n",
    "\n",
    "        regularizer_function = utils.regularizer_functions[regularizer_type]\n",
    "    def objective_function(weights):\n",
    "        loss = 0\n",
    "        \n",
    "        inputs, targets = trainx,trainy\n",
    "        outputs = classify(inputs, weights)\n",
    "        loss += loss_weight*loss_function(targets, outputs)\n",
    "        if regularizer_type != None:\n",
    "            # regulariser function is called from utils.py\n",
    "            loss += regularizer_function(weights)\n",
    "        return loss\n",
    "    return objective_function\n",
    "\n",
    "def get_gradient_function(trainx,trainy,loss_type, regularizer_type, loss_weight):\n",
    "    # This is a way to declare function inside a function \n",
    "    # The get_gradient_function receives the train data from the current batch\n",
    "    # and all other parameters on which the loss function and gradient depend\n",
    "    # like C,regulariser_type and loss function\n",
    "    loss_grad_function = utils.loss_grad_functions[loss_type]\n",
    "    if regularizer_type != None:\n",
    "        regularizer_grad_function = utils.regularizer_grad_functions[regularizer_type]\n",
    "    # gradient function is called from scipy.optimise.minimise()\n",
    "    # the only paramter its can send is weights \n",
    "    # hence there was a need to pass the current batch through get_objective_function\n",
    "\n",
    "\n",
    "    def gradient_function(weights):\n",
    "\n",
    "        gradient = np.zeros(len(weights), dtype=np.float32)\n",
    "        X=trainx\n",
    "        Y=trainy\n",
    "        outputs = classify(X,weights)\n",
    "        # loss_grad_function is called from utils.py\n",
    "        gradient = loss_weight*loss_grad_function(weights,X,Y,outputs)/len(trainx)\n",
    "        if regularizer_type != None:\n",
    "            # regulariser grad function is called from utils.py\n",
    "            gradient += regularizer_grad_function(weights)\n",
    "        return gradient\n",
    "    return gradient_function\n",
    "\n",
    "def train(data_loader, loss_type, regularizer_type, loss_weight):\n",
    "    initial_model_parameters = np.random.random((data_loader.num_features))\n",
    "\n",
    "    num_epochs=1000\n",
    "    for i in range(num_epochs):\n",
    "        loss=0\n",
    "        if(i==0):\n",
    "            start_parameters=initial_model_parameters\n",
    "        for j in range(len(data_loader)):\n",
    "            trainx,trainy=data_loader[j]\n",
    "            objective_function = get_objective_function(trainx,trainy,loss_type, \n",
    "                                                regularizer_type,loss_weight)\n",
    "            gradient_function = get_gradient_function(trainx,trainy, loss_type, \n",
    "                                              regularizer_type, loss_weight)\n",
    "            # to know about this function please read about scipy.optimise.minimise\n",
    "            trained_model_parameters = minimize(objective_function, \n",
    "                                        start_parameters, \n",
    "                                        method=\"CG\", \n",
    "                                        jac=gradient_function,\n",
    "                                        options={'disp': False,\n",
    "                                                 'maxiter': 1})\n",
    "            loss+=objective_function(trained_model_parameters.x)\n",
    "            start_parameters=trained_model_parameters.x\n",
    "        # prints the batch loss\n",
    "        print(\"loss is  \",loss)\n",
    "        \n",
    "    print(\"Optimizer information:\")\n",
    "    print(trained_model_parameters)\n",
    "    return trained_model_parameters.x\n",
    "            \n",
    "\n",
    "def test(inputs, weights):\n",
    "    outputs = classify(inputs, weights)\n",
    "    probs = 1/(1+np.exp(-outputs))\n",
    "    # this is done to get all terms in 0 or 1 You can change for -1 and 1\n",
    "    return np.round(probs)\n",
    "\n",
    "def write_csv_file(outputs, output_file):\n",
    "    # dumps the output file\n",
    "    with open(output_file, \"w\") as out_file:\n",
    "        out_file.write(\"ID, Output\\n\")\n",
    "        for i in range(len(outputs)):\n",
    "            out_file.write(\"{}, {}\".format(i+1, str(outputs[i])) + \"\\n\")\n",
    "def get_data(data_file):\n",
    "    with open(data_file, 'r') as df:\n",
    "        data = df.readlines()\n",
    "\n",
    "    data = data[1:]\n",
    "    data = np.array([[float(col) for col in row.split(',')] for row in data])\n",
    "    input_data = np.hstack([data, np.ones((len(data), 1), dtype=np.float32)])\n",
    "\n",
    "    return input_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got files\n"
     ]
    }
   ],
   "source": [
    "train_data_loader = DataLoader(\"train.csv\", 64)\n",
    "test_data = get_data(\"test.csv\")\n",
    "print(\"Got files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "actual_targets=pd.read_csv(\"targets.csv\")\n",
    "actual_targets=actual_targets.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(actual_targets[:,1]==test_data_output)/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training for c =  1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-720732dc123e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Started training for c = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrained_model_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"square_hinge_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicting outputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtest_data_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrained_model_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3f51a1d8565a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(data_loader, loss_type, regularizer_type, loss_weight)\u001b[0m\n\u001b[0;32m    102\u001b[0m                                         \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgradient_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                                         options={'disp': False,\n\u001b[1;32m--> 104\u001b[1;33m                                                  'maxiter': 1})\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrained_model_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mstart_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrained_model_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tezan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tezan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_cg\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mgrad_calls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyfprime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfprime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m     \u001b[0mgfk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyfprime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[0mxk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tezan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3f51a1d8565a>\u001b[0m in \u001b[0;36mgradient_function\u001b[1;34m(weights)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# loss_grad_function is called from utils.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_weight\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss_grad_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mregularizer_type\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;31m# regulariser grad function is called from utils.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tezan\\IIT Bombay Resources\\IITB Courses\\CS 419\\CS419M_Group\\Assignment2_IML\\assgmt-2-toy dataset\\utils.py\u001b[0m in \u001b[0;36msquare_hinge_grad\u001b[1;34m(weights, inputs, targets, outputs)\u001b[0m\n\u001b[0;32m     35\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m           \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "c_list=[1]\n",
    "for c in c_list:\n",
    "    print(\"Started training for c = \",c)\n",
    "    trained_model_parameters = train(train_data_loader, \"square_hinge_loss\", None, 1)\n",
    "    print(\"Predicting outputs\")\n",
    "    test_data_output = test(test_data, trained_model_parameters)\n",
    "    accuracies.append(np.sum(actual_targets[:,1]==test_data_output)/300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x5aa7070>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xscale('log')\n",
    "plt.plot(c_list,accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Loss with L4 regularization: best accuracy at c=1 (0.937)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
